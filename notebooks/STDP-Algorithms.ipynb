{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from norse.torch.functional import stdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, IntSlider, FloatSlider\n",
    "from functools import partial\n",
    "\n",
    "IntSlider = partial(IntSlider, continuous_update=False)\n",
    "FloatSlider = partial(FloatSlider, continuous_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dw_pre(delay, p_stdp):\n",
    "    \"\"\"Compute the weight change for a pre spike.\"\"\"\n",
    "    pre_spike = torch.tensor([[1.0]]), torch.tensor([[0.0]])\n",
    "    post_spike = torch.tensor([[0.0]]), torch.tensor([[1.0]])\n",
    "    no_spike = torch.tensor([[0.0]]), torch.tensor([[0.0]])\n",
    "    w = torch.tensor([[0.0]], requires_grad=False)\n",
    "    state = stdp.STDPState(t_pre=torch.tensor([[0.0]]), t_post=torch.tensor([[0.0]]))\n",
    "    _, state = stdp.stdp_step_linear(*post_spike, w, state, p_stdp, dt=0.001)\n",
    "    time = -0.001 * np.arange(0, delay)\n",
    "    dw = []\n",
    "    for _ in time:\n",
    "        w = torch.tensor([[0.0]], requires_grad=False)\n",
    "        dw.append(stdp.stdp_step_linear(*pre_spike, w, state, p_stdp, dt=0.001)[0][0])\n",
    "        state = stdp.stdp_step_linear(*no_spike, w, state, p_stdp, dt=0.001)[1]\n",
    "    return time, dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dw_post(delay, p_stdp):\n",
    "    \"\"\"Compute the weight change for a post spike.\"\"\"\n",
    "    pre_spike = torch.tensor([[1.0]]), torch.tensor([[0.0]])\n",
    "    post_spike = torch.tensor([[0.0]]), torch.tensor([[1.0]])\n",
    "    no_spike = torch.tensor([[0.0]]), torch.tensor([[0.0]])\n",
    "    w = torch.tensor([[0.0]], requires_grad=False)\n",
    "    state = stdp.STDPState(t_pre=torch.tensor([[0.0]]), t_post=torch.tensor([[0.0]]))\n",
    "    _, state = stdp.stdp_step_linear(*pre_spike, w, state, p_stdp, dt=0.001)\n",
    "    time = 0.001 * np.arange(0, delay)\n",
    "    dw = []\n",
    "    for _ in time:\n",
    "        w = torch.tensor([[0.0]], requires_grad=False)\n",
    "        dw.append(stdp.stdp_step_linear(*post_spike, w, state, p_stdp, dt=0.001)[0][0])\n",
    "        state = stdp.stdp_step_linear(*no_spike, w, state, p_stdp, dt=0.001)[1]\n",
    "    return time, dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d781db1c494718b2156c5f27c0eae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, continuous_update=False, description='a_pre', max=10.0, step=0.01…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(\n",
    "    a_pre=FloatSlider(min=0.0, max=10.0, step=0.01, value=1.0),\n",
    "    a_post=FloatSlider(min=0.0, max=10.0, step=0.01, value=1.0),\n",
    "    lgt_pre=FloatSlider(min=-3.0, max=1.0, step=0.01, value=-1.50),\n",
    "    lgt_post=FloatSlider(min=-3.0, max=1.0, step=0.01, value=-1.50),\n",
    "    lgη_plus=FloatSlider(min=-8.0, max=0.0, step=0.01, value=-3.0),\n",
    "    lgη_minus=FloatSlider(min=-8.0, max=0.0, step=0.01, value=-3.0),\n",
    "    mu=FloatSlider(min=0.0, max=1.0, step=0.01, value=0.5),\n",
    ")\n",
    "def experiment(a_pre, a_post, lgt_pre, lgt_post, lgη_plus, lgη_minus, mu):\n",
    "    gen_params = partial(\n",
    "        stdp.STDPParameters,\n",
    "        a_pre=a_pre,\n",
    "        a_post=a_post,\n",
    "        tau_pre_inv=10**-lgt_pre,\n",
    "        tau_post_inv=10**-lgt_post,\n",
    "        w_max=10.0,\n",
    "        w_min=-10.0,\n",
    "        eta_plus=10**lgη_plus,\n",
    "        eta_minus=10.0**lgη_minus,\n",
    "        mu=mu,\n",
    "    )\n",
    "    p_add = gen_params(stdp_algorithm=\"additive\")\n",
    "    p_step = gen_params(stdp_algorithm=\"additive_step\")\n",
    "    p_mult = gen_params(stdp_algorithm=\"multiplicative_pow\")\n",
    "    p_relu = gen_params(stdp_algorithm=\"multiplicative_relu\")\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.title(\"STDP Algorithms\")\n",
    "\n",
    "    plt.plot(*dw_pre(100, p_add), \"g-\", label=\"Additive\")\n",
    "    plt.plot(*dw_post(100, p_add), \"g-\")\n",
    "    plt.plot(*dw_pre(100, p_step), \"c--\", label=\"Additive step\")\n",
    "    plt.plot(*dw_post(100, p_step), \"c--\")\n",
    "    plt.plot(*dw_pre(100, p_mult), \"y:\", label=\"Multiplicative pow\")\n",
    "    plt.plot(*dw_post(100, p_mult), \"y:\")\n",
    "    plt.plot(*dw_pre(100, p_relu), \"m-.\", label=\"Multiplicative relu\")\n",
    "    plt.plot(*dw_post(100, p_relu), \"m-.\")\n",
    "\n",
    "    plt.axhline(y=0, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "    plt.axvline(x=0, color=\"gray\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "    plt.xlabel(\"delay [ms]\")\n",
    "    plt.ylabel(\"weight change\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bccn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
